{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed88c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab437634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:9: UserWarning: Parsing dates in %d/%m/%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  data = pd.read_csv('Train/Compiled.csv', parse_dates=['datetime'])\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n",
      "/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[f'load_lag_{i}'] = data['load'].shift(i)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- load_lag_10\n- load_lag_100\n- load_lag_101\n- load_lag_102\n- load_lag_103\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/34/n9z2vp496dx5gwr2m5_w4p780000gn/T/ipykernel_53150/1720740114.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mforecast_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstart_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mforecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_lags\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexogenous_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# Store the first forecasted value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \"\"\"\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_intercept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \"\"\"\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 )\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     def _validate_data(\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- load_lag_10\n- load_lag_100\n- load_lag_101\n- load_lag_102\n- load_lag_103\n- ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from pingouin import partial_corr\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Train/Compiled.csv', parse_dates=['datetime'])\n",
    "\n",
    "# Create lagged features for load\n",
    "num_lags = 168  # Number of past lags\n",
    "for i in range(1, num_lags + 1):\n",
    "    data[f'load_lag_{i}'] = data['load'].shift(i)\n",
    "\n",
    "# Drop rows with missing values due to lagging\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Calculate partial correlations between load and lagged load variables\n",
    "lagged_columns = [f'load_lag_{i}' for i in range(1, num_lags + 1)]\n",
    "partial_correlations = {}\n",
    "for lag_column in lagged_columns:\n",
    "    other_columns = [col for col in lagged_columns if col != lag_column]\n",
    "    data_temp = data[[lag_column, 'load'] + other_columns]\n",
    "    partial_corr_result = partial_corr(data_temp, x=lag_column, y='load', covar=other_columns, method='pearson')\n",
    "    partial_correlation = partial_corr_result['r'][0]\n",
    "    partial_correlations[lag_column] = partial_correlation\n",
    "\n",
    "# Select lags with partial correlations above a certain threshold\n",
    "threshold = 0.05  # You can adjust this threshold\n",
    "selected_lags = [lag for lag, corr in partial_correlations.items() if abs(corr) > threshold]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split data into features (exogenous variables and selected lagged load) and target (load)\n",
    "exogenous_columns = ['pressure_f', 'cloud_cov_f', 'temp_f', 'wind_dir_f', 'wind_sp_f']\n",
    "features = data[lagged_columns + exogenous_columns]\n",
    "target = data['load']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "\n",
    "train_size = 29232\n",
    "train_features, test_features = features[:train_size], features[train_size:]\n",
    "train_target, test_target = target[:train_size], target[train_size:]\n",
    "\n",
    "\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(train_features, train_target)\n",
    "\n",
    "# Initialize an array to store predictions\n",
    "forecast_horizon = 48\n",
    "num_forecasts = len(test_target) // 24 - 1\n",
    "forecasted_values = np.zeros((num_forecasts, forecast_horizon))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Recursive multi-step forecasting\n",
    "for i in range(num_forecasts):\n",
    "    start_index = i * 24\n",
    "    forecast_features = test_features.iloc[start_index : start_index + 1]\n",
    "    forecast = model.predict(forecast_features[selected_lags + exogenous_columns])\n",
    "\n",
    "    # Store the first forecasted value\n",
    "    forecasted_values[i, 0] = forecast\n",
    "\n",
    "    # Update the feature matrix for the next prediction\n",
    "    for lag in range(168,1,-1):\n",
    "        forecast_features[f'load_lag_{lag}'] = forecast_features[f'load_lag_{lag-1}']\n",
    "    forecast_features['load_lag_1'] = forecast\n",
    "\n",
    "    # Perform recursive forecasting for the remaining steps\n",
    "    for j in range(1, forecast_horizon):\n",
    "        forecast = model.predict(forecast_features[selected_lags + exogenous_columns])\n",
    "        forecasted_values[i, j] = forecast\n",
    "\n",
    "        # Update the feature matrix for the next prediction\n",
    "        for lag in range(168,1,-1):\n",
    "            forecast_features[f'load_lag_{lag}'] = forecast_features[f'load_lag_{lag-1}']\n",
    "        forecast_features['load_lag_1'] = forecast\n",
    "\n",
    "        \n",
    "        \n",
    "forecasted_values = pd.DataFrame(data=forecasted_values)\n",
    "\n",
    "test_target_array = np.zeros((num_forecasts, forecast_horizon))\n",
    "for i in range(num_forecasts):\n",
    "    for j in range(forecast_horizon):\n",
    "        test_target_array[i,j] = test_target[29400+24*i+j]\n",
    "test_target_array = pd.DataFrame(data=test_target_array)\n",
    "\n",
    "\n",
    "\n",
    "error_measures = {}\n",
    "for i in range(len(forecasted_values.columns)):\n",
    "    col_name = forecasted_values.columns[i]\n",
    "    \n",
    "    mae = mean_absolute_error(test_target_array[col_name], forecasted_values[col_name])\n",
    "    mse = mean_squared_error(test_target_array[col_name], forecasted_values[col_name])\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    absolute_error = np.abs(test_target_array[col_name] - forecasted_values[col_name])\n",
    "    mape = np.mean(absolute_error / test_target_array[col_name]) * 100\n",
    "    smape = np.mean(2 * absolute_error / (test_target_array[col_name] + forecasted_values[col_name])) * 100\n",
    "    \n",
    "    mase_numerator = np.mean(absolute_error)\n",
    "    mase_denominator = np.mean(np.abs(test_target_array[col_name].diff()))\n",
    "    mase = mase_numerator / mase_denominator\n",
    "    \n",
    "    error_measures[col_name] = [mae, mse, rmse, mape, smape, mase]\n",
    "\n",
    "# Create a DataFrame to display error measures\n",
    "error_df = pd.DataFrame.from_dict(error_measures, orient='index',\n",
    "                                  columns=['MAE', 'MSE', 'RMSE', 'MAPE', 'SMAPE', 'MASE'])\n",
    "\n",
    "error_df\n",
    "\n",
    "for error_measure in error_df.columns:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.bar(error_df.index, error_df[error_measure])\n",
    "    plt.title(f'{error_measure} for Forecasted Values vs. Actual Values')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Error Value')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(0,48), forecasted_values.iloc[1,].values, label='Predicted', linestyle='dashed')\n",
    "plt.plot(range(0,48), test_target_array.iloc[1,].values, label='Actual')\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('Load')\n",
    "plt.title('Actual Load vs Predicted Load (Linear Regression) First 24 Hours')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
