{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "cf634fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from pingouin import partial_corr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "import math, joblib, os\n",
    "import xgboost as xgb\n",
    "from datetime import datetime, timedelta\n",
    "import json, re\n",
    "\n",
    "from pprint import pprint\n",
    "from psycopg2 import sql\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296260c",
   "metadata": {},
   "source": [
    "## Get the required data from the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "bffa0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"fit3164db.cxkhqsoitzhb.ap-southeast-2.rds.amazonaws.com\", \n",
    "    port=5432,\n",
    "    user=\"postgres\",\n",
    "    password=\"fit3164d13edas\",\n",
    "    database = \"testdb\"\n",
    ")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "35397c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"\n",
    "    SELECT * FROM Actuals\n",
    "    WHERE datetime <= '2021-01-15 07:00:00'\n",
    "\"\"\")\n",
    "column_names = [desc[0] for desc in cursor.description]\n",
    "rows = cursor.fetchall()\n",
    "df = pd.DataFrame(rows, columns= column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e4bef",
   "metadata": {},
   "source": [
    "## Some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "29d1677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_column_datatypes(df):\n",
    "\n",
    "    data_types = read_json_file('colTypes.json')\n",
    "\n",
    "    # Iterate through the columns and their desired data types\n",
    "    response = \"\"\n",
    "    valid = True\n",
    "    for column, dtype in data_types.items():\n",
    "        if column in df.columns:\n",
    "            # Attempt to convert the column to the desired data type\n",
    "            df[column] = df[column].astype(dtype)\n",
    "            \n",
    "    return df\n",
    "\n",
    "def sort_df(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values(by='datetime', ascending=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "a9b517c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = change_column_datatypes(df)\n",
    "df = sort_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda09cb0",
   "metadata": {},
   "source": [
    "## Load up the benchmarks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "85526e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive_forecast</th>\n",
       "      <th>seasonal_forecast_daily</th>\n",
       "      <th>seasonal_forecast_weekly</th>\n",
       "      <th>seasonal_forecast_yearly</th>\n",
       "      <th>random_walk_forecast</th>\n",
       "      <th>linear_regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91888.363148</td>\n",
       "      <td>42076.110321</td>\n",
       "      <td>26793.517122</td>\n",
       "      <td>121357.706350</td>\n",
       "      <td>91904.359113</td>\n",
       "      <td>26485.076818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.952818</td>\n",
       "      <td>3.776680</td>\n",
       "      <td>2.438671</td>\n",
       "      <td>10.996623</td>\n",
       "      <td>7.954216</td>\n",
       "      <td>2.415568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101004.828415</td>\n",
       "      <td>56824.441603</td>\n",
       "      <td>36241.256014</td>\n",
       "      <td>142803.227336</td>\n",
       "      <td>101027.406319</td>\n",
       "      <td>35489.071957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naive_forecast  seasonal_forecast_daily  seasonal_forecast_weekly  \\\n",
       "0    91888.363148             42076.110321              26793.517122   \n",
       "1        7.952818                 3.776680                  2.438671   \n",
       "2   101004.828415             56824.441603              36241.256014   \n",
       "\n",
       "   seasonal_forecast_yearly  random_walk_forecast  linear_regression  \n",
       "0             121357.706350          91904.359113       26485.076818  \n",
       "1                 10.996623              7.954216           2.415568  \n",
       "2             142803.227336         101027.406319       35489.071957  "
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks = pd.read_csv(\"Benchmark_Results.csv\")\n",
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473431f",
   "metadata": {},
   "source": [
    "## The forecasting model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "5c4f30d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityForecaster:\n",
    "    \n",
    "    NUM_OF_MODELS = 48\n",
    "    NUM_OF_LAGS = 168\n",
    "    NUM_OF_STEPS = 48\n",
    "\n",
    "    LAST_RETRAIN = datetime.strptime(\"2021-01-15 07:00:00\", '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.exog = self.read_file(\"exog.txt\")\n",
    "        if model == 'xgboost':\n",
    "            self.models = [xgb.XGBRegressor()  for _ in range(self.NUM_OF_MODELS)]\n",
    "        elif model == 'randomforest':\n",
    "            self.models = [RandomForestRegressor()  for _ in range(self.NUM_OF_MODELS)]\n",
    "        elif model == 'linearreg':\n",
    "            self.models = [LinearRegression()  for _ in range(self.NUM_OF_MODELS)]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit_and_predict(self, data):\n",
    "        data = self.transform_data_valid(data)\n",
    "        train, valid = self.split_data(data)\n",
    "        self.fit(train)\n",
    "        preds, actuals, mae, mape, rmse = self.predict_validation(valid)\n",
    "        return preds, actuals, mae, mape, rmse\n",
    "    \n",
    "\n",
    "    def predict_validation(self, data, transformed=True):\n",
    "        if not transformed:\n",
    "            data = self.transform_data(data)\n",
    "        aes, apes, ses = [], [], []  \n",
    "        preds = []\n",
    "        actuals = []\n",
    "        for i in range(self.NUM_OF_MODELS):\n",
    "\n",
    "            x_columns = self.x_cols(i)\n",
    "            y_columns = self.y_cols(i)\n",
    "\n",
    "            valid_x = data[x_columns]\n",
    "            valid_y = data[y_columns].values\n",
    "\n",
    "            current_model = self.models[i]\n",
    "            prediction = current_model.predict(valid_x)\n",
    "\n",
    "            aes += list(self.absolute_errors(valid_y, prediction))\n",
    "            apes += list(self.absolute_perc_errors(valid_y, prediction))\n",
    "            ses += list((self.squared_errors(valid_y, prediction)))\n",
    "            \n",
    "            preds += prediction.tolist()\n",
    "            actuals += list(valid_y)\n",
    "            \n",
    "        mae = self.get_mae(aes)\n",
    "        mape = self.get_mape(apes)\n",
    "        rmse = self.get_rmse(ses)\n",
    "        \n",
    "        print(f\"mae: {mae}\")\n",
    "        print(f\"mape: {mape}\")\n",
    "        print(f\"rmse: {rmse}\")\n",
    "        \n",
    "        return preds,actuals,  mae, mape, rmse\n",
    "    \n",
    "\n",
    "    def predict_multiple(self, data, transformed = False):\n",
    "        aes, apes, ses = [], [], []  \n",
    "        preds = []\n",
    "        actuals = []\n",
    "        errors = []\n",
    "        if not transformed:\n",
    "            data = self.transform_data(data)\n",
    "        smaller_dfs = [data[i:i + 1] for i in range(0, len(data))]\n",
    "        for i in range(len(smaller_dfs)):\n",
    "             \n",
    "            row = smaller_dfs[i]\n",
    "            \n",
    "            print(row)\n",
    "            \n",
    "            prediction, actual, ae, ape, se = self.predict_48_hours_validation(row, False)\n",
    "            aes += ae\n",
    "            apes += ape\n",
    "            ses += se\n",
    "            preds += prediction\n",
    "            actuals += actual\n",
    "            \n",
    "            start_datetime = row.index.to_pydatetime()[0]\n",
    "            end_datetime = start_datetime + timedelta(hours= self.NUM_OF_STEPS -1 )\n",
    "            new_row = [start_datetime, end_datetime, self.get_mae(ae), self.get_mape(ape), self.get_rmse(aes)]\n",
    "            errors.append(new_row)\n",
    "            print(start_datetime)\n",
    "            print(new_row)\n",
    "            print(ae)\n",
    "            print(ape)\n",
    "            print(se)\n",
    "            print(\"\\n\\n\\n\")\n",
    "\n",
    "            \n",
    "        mae = self.get_mae(aes)\n",
    "        mape = self.get_mape(apes)\n",
    "        rmse = self.get_rmse(ses)\n",
    "        \n",
    "        errors = pd.DataFrame(errors, columns=['start_datetime', 'end_datetime', 'mae', 'mape', 'rmse'])\n",
    "        \n",
    "        print(f\"mae: {mae}\")\n",
    "        print(f\"mape: {mape}\")\n",
    "        print(f\"rmse: {rmse}\")\n",
    "        \n",
    "        return preds,actuals,  mae, mape, rmse, errors\n",
    "    \n",
    "\n",
    "    def predict(self, data, transformed = False):\n",
    "        preds = []\n",
    "\n",
    "        smaller_dfs = self.get_smaller_dfs(data)\n",
    "        for i in range(len(smaller_dfs)):\n",
    "             \n",
    "            row = smaller_dfs[i]\n",
    "\n",
    "            print(\"before transformation: \")\n",
    "            print(row)\n",
    "\n",
    "            if not transformed:\n",
    "                row = self.transform_data(row)\n",
    "            \n",
    "            print(\"After: \")\n",
    "            print(row)\n",
    "            \n",
    "            print(\"predicting 48 hours\")\n",
    "            prediction= self.predict_48_hours(row)\n",
    "\n",
    "            preds += prediction\n",
    "\n",
    "            print(preds)\n",
    "            print(\"\\n\\n\\n\")\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    \n",
    "    def predict_48_hours(self,row):\n",
    "        preds = []\n",
    "        for i in range(self.NUM_OF_MODELS):\n",
    "\n",
    "            x_columns = self.x_cols(i)\n",
    "\n",
    "            valid_x = row[x_columns]\n",
    "\n",
    "            current_model = self.models[i]\n",
    "            prediction = current_model.predict(valid_x)\n",
    "\n",
    "            preds += prediction.tolist()\n",
    "\n",
    "        self.save_predictions_to_db(preds, row)\n",
    "                \n",
    "        return preds\n",
    "    \n",
    "\n",
    "    def predict_48_hours_validation(self,row, once=True):\n",
    "        aes, apes, ses = [], [], []  \n",
    "        preds = []\n",
    "        actuals = []\n",
    "        start_datetime = row.index.to_pydatetime()[0]\n",
    "        for i in range(self.NUM_OF_MODELS):\n",
    "\n",
    "            x_columns = self.x_cols(i)\n",
    "            y_columns = self.y_cols(i)\n",
    "\n",
    "            valid_x = row[x_columns]\n",
    "            valid_y = row[y_columns].values\n",
    "\n",
    "            current_model = self.models[i]\n",
    "            prediction = current_model.predict(valid_x)\n",
    "            preds += prediction.tolist()\n",
    "            actuals += list(valid_y)\n",
    "            \n",
    "            aes += list(self.absolute_errors(valid_y, prediction))\n",
    "            apes += list(self.absolute_perc_errors(valid_y, prediction))\n",
    "            ses += list((self.squared_errors(valid_y, prediction)))\n",
    "            \n",
    "        mae = self.get_mae(aes)\n",
    "        mape = self.get_mape(apes)\n",
    "        rmse = self.get_rmse(ses)\n",
    "\n",
    "        self.save_valid_data(row, actuals, preds)\n",
    "        \n",
    "        if not once:\n",
    "            return preds, actuals, aes, apes, ses\n",
    "        \n",
    "        return preds, actuals, mae, mape, rmse\n",
    "    \n",
    "        \n",
    "    def fit(self,data, transformed=True):\n",
    "        if not transformed:\n",
    "            data = self.transform_data_valid(data)\n",
    "#         models_mp = joblib.Parallel(n_jobs=8)(\n",
    "#     joblib.delayed(self.fit_on_model)(data, model_index) for model_index in range(self.NUM_OF_MODELS)\n",
    "# )\n",
    "        for i in range(self.NUM_OF_MODELS):\n",
    "            self.fit_on_model(data, i)\n",
    "\n",
    "        print(\"fitted\")\n",
    "\n",
    "            \n",
    "    def fit_on_model(self, data, i):\n",
    "        x_columns = self.x_cols(i)\n",
    "        y_columns = self.y_cols(i)\n",
    "\n",
    "        train_x = data[x_columns]\n",
    "        train_y = data[y_columns]\n",
    "\n",
    "        current_model = self.models[i]\n",
    "        current_model.fit(train_x, train_y)\n",
    "        \n",
    "            \n",
    "    def save_predictions_to_db(self, predictions, row):\n",
    "        timestep = timedelta(hours=1)\n",
    "\n",
    "        current_datetime = row.index.to_pydatetime()[0]\n",
    "\n",
    "        print(f\"number of predictions: {len(predictions)}\")\n",
    "\n",
    "        for i in range(len(predictions)):\n",
    "\n",
    "            print(f\"i: {i}\")\n",
    "            #save to predictions first:\n",
    "            load = predictions[i]  # Assuming you have a list of load values\n",
    "            \n",
    "            query = sql.SQL(\"\"\"\n",
    "                INSERT INTO pracpredictions (datetime, load)\n",
    "                VALUES (%s, %s)\n",
    "                ON CONFLICT (datetime) DO UPDATE\n",
    "                SET load = excluded.load\n",
    "            \"\"\")\n",
    "\n",
    "            cursor.execute(query, (current_datetime, load))\n",
    "            conn.commit()\n",
    "\n",
    "            # save to actuals:\n",
    "            # row/predictions should be 48 \n",
    "            # row: datetime, lags, leads\n",
    "            forecasts = self.get_lead_forecast_names(i)\n",
    "            date_decomp = self.get_date_decomp(current_datetime)\n",
    "            actuals = [current_datetime] + [load] + row[forecasts].values.tolist()[0] + date_decomp\n",
    "\n",
    "            datetime, load, pressure, temperature, cloud_cover, wind_direction, wind_speed, date, month, hour, type_of_day = actuals\n",
    "\n",
    "            query = sql.SQL(\"\"\"\n",
    "                INSERT INTO actuals (datetime, load, pressure, temperature, cloud_cover, wind_direction, wind_speed, date, month, hour, type_of_day)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (datetime) DO UPDATE\n",
    "                SET\n",
    "                    load = excluded.load,\n",
    "                    pressure = excluded.pressure,\n",
    "                    temperature = excluded.temperature,\n",
    "                    cloud_cover = excluded.cloud_cover,\n",
    "                    wind_direction = excluded.wind_direction,\n",
    "                    wind_speed = excluded.wind_speed,\n",
    "                    date = excluded.date,\n",
    "                    month = excluded.month,\n",
    "                    hour = excluded.hour,\n",
    "                    type_of_day = excluded.type_of_day\n",
    "            \"\"\")\n",
    "\n",
    "            cursor.execute(\n",
    "                query,\n",
    "                (datetime, load, pressure, temperature, cloud_cover, wind_direction, wind_speed, date, month, hour, type_of_day)\n",
    "            )\n",
    "            conn.commit()\n",
    "\n",
    "\n",
    "            print(\"saved to actuals\")\n",
    "            # Increment the datetime by an hour for the next iteration\n",
    "            current_datetime += timestep\n",
    "\n",
    "\n",
    "    def save_valid_data(self, row, actuals, preds):\n",
    "        current_datetime = row.index.to_pydatetime()[0]\n",
    "        timestep = timedelta(hours=1)\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            print(f\"i: {i}\")\n",
    "            prediction = preds[i]\n",
    "\n",
    "            query = sql.SQL(\"\"\"\n",
    "                INSERT INTO pracpredictions (datetime, load)\n",
    "                VALUES (%s, %s)\n",
    "                ON CONFLICT (datetime) DO UPDATE\n",
    "                SET load = excluded.load\n",
    "            \"\"\")\n",
    "\n",
    "            cursor.execute(query, (current_datetime, prediction))\n",
    "            conn.commit()\n",
    "\n",
    "            actual = actuals[i]\n",
    "            forecasts = self.get_lead_forecast_names(i)\n",
    "            date_decomp = self.get_date_decomp(current_datetime)\n",
    "            print(f\"actual: {actual}\")\n",
    "            print(f\"forecasts: {forecasts}\")\n",
    "            print(f\"date_decomp: {date_decomp}\")\n",
    "            actual_row = [current_datetime] + [actual] + row[forecasts].values.tolist()[0] + date_decomp\n",
    "            \n",
    "            datetime, actual, pressure, temperature, cloud_cover, wind_direction, wind_speed, date, month, hour, type_of_day = actual_row\n",
    "\n",
    "            # Save to 'actuals'\n",
    "            query = sql.SQL(\"\"\"\n",
    "                INSERT INTO actuals (datetime, load, pressure, temperature, cloud_cover, wind_direction, wind_speed, date, month, hour, type_of_day)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                ON CONFLICT (datetime) DO UPDATE\n",
    "                SET\n",
    "                    load = excluded.load,\n",
    "                    pressure = excluded.pressure,\n",
    "                    temperature = excluded.temperature,\n",
    "                    cloud_cover = excluded.cloud_cover,\n",
    "                    wind_direction = excluded.wind_direction,\n",
    "                    wind_speed = excluded.wind_speed,\n",
    "                    date = excluded.date,\n",
    "                    month = excluded.month,\n",
    "                    hour = excluded.hour,\n",
    "                    type_of_day = excluded.type_of_day\n",
    "            \"\"\")\n",
    "            cursor.execute(\n",
    "                query,\n",
    "                (datetime, actual, pressure, temperature, cloud_cover, wind_direction, wind_speed, date, month, hour, type_of_day)\n",
    "            )\n",
    "            conn.commit()\n",
    "            \n",
    "            current_datetime += timestep\n",
    "\n",
    "   \n",
    "    def add_lags(self, df):\n",
    "\n",
    "        #because the user may request to re-predict on dates that are already predicted on\n",
    "        last_date_df = df['datetime'].min()\n",
    "        # if last_date_db > last_date_df:\n",
    "        #     current_date = last_date_df\n",
    "        # else:\n",
    "        #     current_date = last_date_db\n",
    "        current_date = last_date_df\n",
    "        end_date = current_date - timedelta(hours=1)\n",
    "        start_date = current_date - timedelta(days=7)\n",
    "        \n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT * FROM Actuals\n",
    "            WHERE datetime >= '{start_date}' AND datetime <= '{end_date}'\n",
    "        \"\"\")\n",
    "        column_names = [desc[0] for desc in cursor.description]\n",
    "        rows = cursor.fetchall()\n",
    "        db_data = pd.DataFrame(rows, columns= column_names)\n",
    "        db_data = db_data.drop(columns=['id'])\n",
    "\n",
    "#         rows = Actuals.objects.filter(datetime__range=(start_date, end_date))\n",
    "#         db_data = self.get_df(list(rows.values())).drop(columns=['id'])\n",
    "\n",
    "        full_df = pd.concat([db_data, df]).sort_values(by='datetime')\n",
    "\n",
    "        full_df = full_df.reset_index(drop=True)\n",
    "        full_df = self.sort_df(full_df)\n",
    "\n",
    "        print(\"lags: \")\n",
    "        print(full_df)\n",
    "\n",
    "        return full_df\n",
    "\n",
    "    def get_date_decomp(self, datetime):\n",
    "        date = datetime.date()\n",
    "        month = datetime.month\n",
    "        hour = datetime.hour\n",
    "        type_of_day = datetime.isoweekday()\n",
    "\n",
    "        return [date, month, hour, type_of_day]\n",
    "\n",
    "\n",
    "    def transform_data(self, data):\n",
    "\n",
    "        #add the lags from the db\n",
    "        data = self.add_lags(data)\n",
    "\n",
    "        data = self.change_column_datatypes(data)\n",
    "\n",
    "        #cyclical encoding first\n",
    "        data = self.encode(data, 'hour', 24)\n",
    "        data = self.encode(data, 'month', 12)\n",
    "        data = self.encode(data, 'type_of_day', 31)\n",
    "\n",
    "        data = self.remove_extras(data)\n",
    "\n",
    "        data = self.get_lag_lead(data)\n",
    "        \n",
    "        print(\"lag lead: \")\n",
    "        print(data)\n",
    "\n",
    "        #get 8 am hour rows\n",
    "        data = self.condense_data(data)\n",
    "\n",
    "        \n",
    "        print(\"condensed: \")\n",
    "        print(data)\n",
    "        # set datetime as index:\n",
    "        data = self.set_datetime_index(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "\n",
    "    def transform_data_valid(self, data):\n",
    "\n",
    "        data = self.change_column_datatypes(data)\n",
    "\n",
    "        #cyclical encoding first\n",
    "        data = self.encode(data, 'hour', 24)\n",
    "        data = self.encode(data, 'month', 12)\n",
    "        data = self.encode(data, 'type_of_day', 31)\n",
    "    \n",
    "        data = self.remove_extras(data)      \n",
    "\n",
    "        #get the lags and leads\n",
    "        data = self.get_lag_lead_for_valid(data)\n",
    "        \n",
    "        #get 8 am hour rows\n",
    "        data = self.condense_data_valid(data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def absolute_errors(self, actuals, predicted):\n",
    "        ae = np.abs(actuals-predicted)\n",
    "        return ae\n",
    "\n",
    "    def squared_errors(self, actuals, predicted):\n",
    "        se = np.square(actuals-predicted )\n",
    "        return se\n",
    "\n",
    "    def absolute_perc_errors(self, actuals, predicted):\n",
    "        ape = ((np.abs(actuals-predicted))/ actuals) * 100\n",
    "        return ape\n",
    "    \n",
    "    def get_mae(self, aes):\n",
    "        return np.mean(aes)\n",
    "\n",
    "    def get_rmse(self, ses):\n",
    "        return np.sqrt(np.mean(ses))\n",
    "\n",
    "    def get_mape(self, apes):\n",
    "        return np.mean(apes)\n",
    "\n",
    "    #get specific lead forecast column names from whole df for each model\n",
    "    def get_lead_forecast_names(self, i):\n",
    "        cols = self.exog\n",
    "        lead_cols = []\n",
    "        for c in cols: \n",
    "            lead_cols.append(f'{c}_lead_{i}')\n",
    "        return lead_cols\n",
    "\n",
    "\n",
    "    def x_cols(self, i):\n",
    "        # Specify the text file\n",
    "        word_list = self.read_file('train_cols.txt')\n",
    "\n",
    "        word_list += self.get_lead_forecast_names(i)\n",
    "\n",
    "        return word_list\n",
    "\n",
    "\n",
    "    def y_cols(self, i):\n",
    "        return f'load_lead_{i}'\n",
    "\n",
    "\n",
    "    def split_data(self, data, test_size=0.1):\n",
    "        return np.split(data, [int((1 - test_size) * data.shape[0]) + 1])  \n",
    "    \n",
    "\n",
    "    def condense_data_valid(self, data):\n",
    "        \n",
    "        desired_start_time = '08:00:00'\n",
    "        desired_datetime = pd.to_datetime(desired_start_time).time()\n",
    "        filtered_df = data.between_time(desired_datetime, desired_datetime)\n",
    "#         filtered_df.dropna(inplace = True) # drop any nulls just in case\n",
    "        return filtered_df\n",
    "        \n",
    "\n",
    "    def condense_data(self, data):\n",
    "        desired_start_time = '08:00:00'\n",
    "        desired_datetime = pd.to_datetime(desired_start_time).time()\n",
    "        filtered_df = data[data['datetime'].apply(lambda x: pd.to_datetime(x).time() == desired_datetime)]\n",
    "        filtered_df.dropna(inplace = True) # drop any nulls just in case\n",
    "        return filtered_df\n",
    "    \n",
    "\n",
    "    def remove_extras(self, data):\n",
    "        to_remove = ['date','month', 'hour', 'type_of_day', 'date']\n",
    "        data = data.drop(to_remove, axis=1)\n",
    "        data = data.rename(columns = {'type_of_day_sin': 'day_sin', \n",
    "                            'type_of_day_cos': 'day_cos'})\n",
    "        return data\n",
    "    \n",
    "\n",
    "    def get_lag_lead_for_valid(self, data, num_lags=168, forward_pred=48): \n",
    "        cols = self.exog + ['load']\n",
    "        #for load\n",
    "        for i in range(1, self.NUM_OF_LAGS + 1):\n",
    "            data[f'load_lag_{i}'] = data['load'].shift(i) \n",
    "\n",
    "        #for lagged weather variables\n",
    "        for c in self.exog:\n",
    "            for i in range(1, self.NUM_OF_LAGS+1):\n",
    "                data[f'{c}_lag_{i}'] = data[c].shift(i)\n",
    "\n",
    "        for i in range(0, self. NUM_OF_STEPS):    \n",
    "            data[f'load_lead_{i}'] = data['load'].shift(-i)\n",
    "\n",
    "        #weather\n",
    "        for c in self.exog:\n",
    "            for i in range(0,self. NUM_OF_STEPS):\n",
    "                data[f'{c}_lead_{i}'] = data[c].shift(-i)\n",
    "\n",
    "\n",
    "        data = data.drop(cols, axis=1)\n",
    "        data.dropna(inplace = True)    #drop nulls\n",
    "        data = data.set_index('datetime')   #set index as datetime\n",
    "        data = data.asfreq('H')\n",
    "\n",
    "        return data\n",
    "    \n",
    "\n",
    "    def get_lag_lead(self, data, num_lags=168, forward_pred=48): \n",
    "        cols = self.exog\n",
    "        to_remove = cols + ['load']\n",
    "        #for lagged load\n",
    "        for i in range(1, self.NUM_OF_LAGS + 1):\n",
    "            data[f'load_lag_{i}'] = data['load'].shift(i) \n",
    "\n",
    "        #for lagged weather variables\n",
    "        for c in self.exog:\n",
    "            for i in range(1, self.NUM_OF_LAGS+1):\n",
    "                data[f'{c}_lag_{i}'] = data[c].shift(i)\n",
    "\n",
    "\n",
    "        #weather\n",
    "        for c in self.exog:\n",
    "            for i in range(0,self.NUM_OF_STEPS):\n",
    "                data[f'{c}_lead_{i}'] = data[c].shift(-i)\n",
    "\n",
    "        data = data.drop(to_remove, axis=1)\n",
    "     \n",
    "        data.dropna(inplace = True)    #drop nulls\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def set_datetime_index(self, data):\n",
    "        data = data.set_index('datetime')   #set index as datetime\n",
    "        data = data.asfreq('H')\n",
    "        return data\n",
    "\n",
    "\n",
    "    def encode(self, data, col, max_val):\n",
    "        data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "        data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "        return data\n",
    "    \n",
    "\n",
    "    def get_smaller_dfs(self, df):\n",
    "        sub_dataframes = []\n",
    "        chunk_size = self.NUM_OF_STEPS\n",
    "        step_size = chunk_size // 2\n",
    "\n",
    "        # Iterate through the original DataFrame and split it into chunks\n",
    "        for i in range(0, len(df) - chunk_size + 1, step_size):\n",
    "            chunk = df.iloc[i:i + chunk_size]\n",
    "            \n",
    "            # Check if the chunk size is equal to the specified size (48 rows)\n",
    "            if len(chunk) == chunk_size:\n",
    "                sub_dataframes.append(chunk)\n",
    "        return sub_dataframes\n",
    "\n",
    "\n",
    "    def change_column_datatypes(self, df):\n",
    "\n",
    "        data_types = self.read_json_file('colTypes.json')\n",
    "\n",
    "        for column, dtype in data_types.items():\n",
    "            try:\n",
    "                # Attempt to convert the column to the desired data type\n",
    "                df[column] = df[column].astype(dtype)\n",
    "\n",
    "            except (ValueError, TypeError, KeyError):\n",
    "                # Handle any potential errors (e.g., if conversion is not possible)\n",
    "                response = f\"Error converting '{column}' to {dtype}\"\n",
    "                valid = False\n",
    "            \n",
    "        return df\n",
    "\n",
    "    \n",
    "    def read_file(self, filename):\n",
    "        # Initialize an empty list to store the words\n",
    "        word_list = []\n",
    "        # Open the file and read its contents line by line\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                # Remove leading and trailing whitespace and append the word to the list\n",
    "                word_list.append(line.strip())\n",
    "        return word_list\n",
    "    \n",
    "\n",
    "\n",
    "    def read_json_file(self, filename):\n",
    "        with open(filename, \"r\") as json_file:\n",
    "            file = json.load(json_file)\n",
    "        return file\n",
    "    \n",
    "    def save_model(self):\n",
    "        filename = \"ElectricityDemandForecaster.joblib\"\n",
    "        joblib.dump(self, filename)\n",
    "\n",
    "    \n",
    "    def sort_df(self, df):\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        df = df.sort_values(by='datetime', ascending=True)\n",
    "        return df\n",
    "    \n",
    "\n",
    "\n",
    "    def get_df(self, data):\n",
    "        data =  pd.DataFrame(data)\n",
    "        data = self.sort_df(data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff63fc",
   "metadata": {},
   "source": [
    "### XGBoost:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806b51bd",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "b20579f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted\n"
     ]
    }
   ],
   "source": [
    "model = ElectricityForecaster(\"xgboost\")\n",
    "data = model.transform_data_valid(df)\n",
    "train, valid = model.split_data(data)\n",
    "model.fit(train, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69834f0d",
   "metadata": {},
   "source": [
    "#### Predicting on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "4aff0372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 26460.963007688853\n",
      "mape: 2.408141781373403\n",
      "rmse: 37274.37019047834\n"
     ]
    }
   ],
   "source": [
    "preds,actuals,  xg_mae, xg_mape, xg_rmse = model.predict_validation(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "9f257174",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_errors = pd.DataFrame(data= {\"xboost\": [mae, mape, rmse]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "d975122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive_forecast</th>\n",
       "      <th>seasonal_forecast_daily</th>\n",
       "      <th>seasonal_forecast_weekly</th>\n",
       "      <th>seasonal_forecast_yearly</th>\n",
       "      <th>random_walk_forecast</th>\n",
       "      <th>linear_regression</th>\n",
       "      <th>xboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91888.363148</td>\n",
       "      <td>42076.110321</td>\n",
       "      <td>26793.517122</td>\n",
       "      <td>121357.706350</td>\n",
       "      <td>91904.359113</td>\n",
       "      <td>26485.076818</td>\n",
       "      <td>26460.963008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.952818</td>\n",
       "      <td>3.776680</td>\n",
       "      <td>2.438671</td>\n",
       "      <td>10.996623</td>\n",
       "      <td>7.954216</td>\n",
       "      <td>2.415568</td>\n",
       "      <td>2.408142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101004.828415</td>\n",
       "      <td>56824.441603</td>\n",
       "      <td>36241.256014</td>\n",
       "      <td>142803.227336</td>\n",
       "      <td>101027.406319</td>\n",
       "      <td>35489.071957</td>\n",
       "      <td>37274.370190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naive_forecast  seasonal_forecast_daily  seasonal_forecast_weekly  \\\n",
       "0    91888.363148             42076.110321              26793.517122   \n",
       "1        7.952818                 3.776680                  2.438671   \n",
       "2   101004.828415             56824.441603              36241.256014   \n",
       "\n",
       "   seasonal_forecast_yearly  random_walk_forecast  linear_regression  \\\n",
       "0             121357.706350          91904.359113       26485.076818   \n",
       "1                 10.996623              7.954216           2.415568   \n",
       "2             142803.227336         101027.406319       35489.071957   \n",
       "\n",
       "         xboost  \n",
       "0  26460.963008  \n",
       "1      2.408142  \n",
       "2  37274.370190  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = pd.concat([benchmarks, xgboost_errors], axis=1)\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b03b2b6",
   "metadata": {},
   "source": [
    "### Random Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb310c8",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "8647bdd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted\n"
     ]
    }
   ],
   "source": [
    "rf_model = ElectricityForecaster(\"randomforest\")\n",
    "data = rf_model.transform_data_valid(df)\n",
    "train, valid = rf_model.split_data(data)\n",
    "rf_model.fit(train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "1ef6f137",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 21465.227062322898\n",
      "mape: 1.9419149608766686\n",
      "rmse: 31865.829409425733\n"
     ]
    }
   ],
   "source": [
    "preds,actuals,  rf_mae, rf_mape, rf_rmse = rf_model.predict_validation(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "e8218b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_errors = pd.DataFrame(data= {\"random_forest\": [rf_mae, rf_mape, rf_rmse]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "b5953f6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive_forecast</th>\n",
       "      <th>seasonal_forecast_daily</th>\n",
       "      <th>seasonal_forecast_weekly</th>\n",
       "      <th>seasonal_forecast_yearly</th>\n",
       "      <th>random_walk_forecast</th>\n",
       "      <th>linear_regression</th>\n",
       "      <th>xboost</th>\n",
       "      <th>random_forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91888.363148</td>\n",
       "      <td>42076.110321</td>\n",
       "      <td>26793.517122</td>\n",
       "      <td>121357.706350</td>\n",
       "      <td>91904.359113</td>\n",
       "      <td>26485.076818</td>\n",
       "      <td>26460.963008</td>\n",
       "      <td>21465.227062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.952818</td>\n",
       "      <td>3.776680</td>\n",
       "      <td>2.438671</td>\n",
       "      <td>10.996623</td>\n",
       "      <td>7.954216</td>\n",
       "      <td>2.415568</td>\n",
       "      <td>2.408142</td>\n",
       "      <td>1.941915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101004.828415</td>\n",
       "      <td>56824.441603</td>\n",
       "      <td>36241.256014</td>\n",
       "      <td>142803.227336</td>\n",
       "      <td>101027.406319</td>\n",
       "      <td>35489.071957</td>\n",
       "      <td>37274.370190</td>\n",
       "      <td>31865.829409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naive_forecast  seasonal_forecast_daily  seasonal_forecast_weekly  \\\n",
       "0    91888.363148             42076.110321              26793.517122   \n",
       "1        7.952818                 3.776680                  2.438671   \n",
       "2   101004.828415             56824.441603              36241.256014   \n",
       "\n",
       "   seasonal_forecast_yearly  random_walk_forecast  linear_regression  \\\n",
       "0             121357.706350          91904.359113       26485.076818   \n",
       "1                 10.996623              7.954216           2.415568   \n",
       "2             142803.227336         101027.406319       35489.071957   \n",
       "\n",
       "         xboost  random_forest  \n",
       "0  26460.963008   21465.227062  \n",
       "1      2.408142       1.941915  \n",
       "2  37274.370190   31865.829409  "
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = pd.concat([errors, randomforest_errors], axis=1)\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f78e947",
   "metadata": {},
   "source": [
    "### Linear Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d683a15",
   "metadata": {},
   "source": [
    "#### Fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d9f22e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted\n"
     ]
    }
   ],
   "source": [
    "lr_model = ElectricityForecaster(\"linearreg\")\n",
    "data = lr_model.transform_data_valid(df)\n",
    "train, valid = lr_model.split_data(data)\n",
    "lr_model.fit(train, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "34428266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 129415.16430784251\n",
      "mape: 11.669856303542343\n",
      "rmse: 193484.4949304263\n"
     ]
    }
   ],
   "source": [
    "preds,actuals, lr_mae, lr_mape, lr_rmse = lr_model.predict_validation(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "0d4ad813",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors['linear_regression'] = [lr_mae, lr_mape, lr_rmse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "b549d8e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive_forecast</th>\n",
       "      <th>seasonal_forecast_daily</th>\n",
       "      <th>seasonal_forecast_weekly</th>\n",
       "      <th>seasonal_forecast_yearly</th>\n",
       "      <th>random_walk_forecast</th>\n",
       "      <th>linear_regression</th>\n",
       "      <th>xboost</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91888.363148</td>\n",
       "      <td>42076.110321</td>\n",
       "      <td>26793.517122</td>\n",
       "      <td>121357.706350</td>\n",
       "      <td>91904.359113</td>\n",
       "      <td>129415.164308</td>\n",
       "      <td>26460.963008</td>\n",
       "      <td>21465.227062</td>\n",
       "      <td>MAE</td>\n",
       "      <td>MAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.952818</td>\n",
       "      <td>3.776680</td>\n",
       "      <td>2.438671</td>\n",
       "      <td>10.996623</td>\n",
       "      <td>7.954216</td>\n",
       "      <td>11.669856</td>\n",
       "      <td>2.408142</td>\n",
       "      <td>1.941915</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>MAPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101004.828415</td>\n",
       "      <td>56824.441603</td>\n",
       "      <td>36241.256014</td>\n",
       "      <td>142803.227336</td>\n",
       "      <td>101027.406319</td>\n",
       "      <td>193484.494930</td>\n",
       "      <td>37274.370190</td>\n",
       "      <td>31865.829409</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>RMSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   naive_forecast  seasonal_forecast_daily  seasonal_forecast_weekly  \\\n",
       "0    91888.363148             42076.110321              26793.517122   \n",
       "1        7.952818                 3.776680                  2.438671   \n",
       "2   101004.828415             56824.441603              36241.256014   \n",
       "\n",
       "   seasonal_forecast_yearly  random_walk_forecast  linear_regression  \\\n",
       "0             121357.706350          91904.359113      129415.164308   \n",
       "1                 10.996623              7.954216          11.669856   \n",
       "2             142803.227336         101027.406319      193484.494930   \n",
       "\n",
       "         xboost  random_forest metric model  \n",
       "0  26460.963008   21465.227062    MAE   MAE  \n",
       "1      2.408142       1.941915   MAPE  MAPE  \n",
       "2  37274.370190   31865.829409   RMSE  RMSE  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "de216ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.to_csv(\"errors.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
